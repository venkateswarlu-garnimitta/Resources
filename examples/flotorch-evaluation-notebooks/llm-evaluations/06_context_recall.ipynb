{"cells":[{"cell_type":"markdown","metadata":{"id":"SLM1c8HVb23D"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/1QNILXJMSKUPHozqmSIq-tsHqpHRAFNPp/view?usp=sharing)\n","\n","# Evaluating the Network Security Protocol Advisor with Flotorch Eval"]},{"cell_type":"markdown","metadata":{"id":"POKsV852T0Rd"},"source":["This notebook provides a step-by-step guide to **evaluate a question-answering agent (RAG)** using the **Flotorch SDK** and **Flotorch Eval** library.  \n","The use case here is a **Network Security Protocol Advisor** — an LLM-powered assistant that answers operational and architectural questions about the \"**Network Security Protocols – Comprehensive Guide**\" covering encryption standards, authentication layers, VPN designs, wireless hardening, email security, and best-practice implementations across the OSI stack.\n","\n","---\n","\n","\n","### **Use Case Overview**\n","\n","The **Network Security Protocol Advisor** helps SecOps teams, architects, and auditors quickly retrieve grounded guidance on:\n","- **Encryption Protocols** (TLS handshake hardening, IPsec modes, AES modes, RSA vs. ECC tradeoffs)\n","- **Authentication Protocols** (Kerberos ticket flows, AD/LDAP binding over TLS, RADIUS vs. TACACS+ AAA policies, OAuth 2.0 and OpenID Connect safeguards)\n","- **Virtual Private Networks** (site-to-site IPsec negotiation, SSL/TLS clientless access, WireGuard key distribution, HA/failover topologies)\n","- **Wireless Security** (WPA3 SAE, 802.1X/EAP methods, WIDS/WIPS containment, Bluetooth and IoT segmentation strategies)\n","- **Email/Web/Perimeter Security** (SPF/DKIM/DMARC enforcement, web security controls, firewall ACL design, intrusion detection/prevention tuning)\n","\n","Relevant passages are retrieved from the **Network Security Knowledge Base** compiled from the comprehensive guide above, ensuring that every answer maps back to vetted implementation details and policy controls.\n","\n","This notebook focuses on evaluating **retrieval faithfulness** using the **DeepEval Context Recall metric** — verifying that the assistant consistently pulls the *right* network security passages so its answers cite encryption suites, AAA flows, tunneling modes, or monitoring steps found in the source documentation.\n","\n","---\n","\n","### **Notebook Workflow**\n","\n","We'll follow a structured evaluation process:\n","\n","1. **Iterate Questions** – Loop through each network security scenario in the ground-truth set.  \n","2. **Retrieve Context** – Fetch relevant protocol guidance from the Network Security Knowledge Base.  \n","3. **Generate Answer** – Use the system prompt and LLM to produce a technically sound response.  \n","4. **Store Results** – Log each question, retrieved context, generated answer, and reference answer.  \n","5. **Evaluate Context Recall** – Use `LLMEvaluator` from Flotorch Eval to run the DeepEval Context Recall check.  \n","6. **Display Results** – Summarize recall outcomes in an at-a-glance table.\n","\n","---\n","\n","### **Metric Evaluated — Context Recall**\n","\n","We track **Context Recall** to ensure the assistant leverages all *relevant* portions of the underlying network security corpus. A score of 1 indicates the retrieved snippets contained the critical facts (cipher negotiation steps, AAA requirements, IDS workflows) needed to answer the question; 0 means the assistant missed essential context or relied on unrelated passages.\n","\n","#### DeepEval Context Recall (Flotorch `evaluation_engine=\"deepeval\"`)\n","- Compares the generated answer with the reference answer and cited context snippets to determine whether the supporting evidence fully covers the required facts.  \n","- Highlights retrieval gaps so teams can expand the knowledge base, adjust search parameters, or refine prompt instructions.  \n","- Prioritizes *coverage* over style, which is crucial when validating that VPN runbooks, WPA3 onboarding steps, or SPF/DKIM policies were surfaced before the model responded.\n","\n","---\n","\n","### **Evaluation Engine**\n","\n","- `evaluation_engine=\"auto\"` — lets Flotorch Eval mix Ragas and DeepEval according to the priority routing described in the [flotorch-eval repo](https://github.com/FissionAI/flotorch-eval/tree/develop) (Ragas first, DeepEval as fallback) so that faithfulness, answer relevance, and context metrics always run on the best available backend.\n","- `evaluation_engine=\"deepeval\"` — routes metrics through DeepEval’s engine (faithfulness, answer relevancy, context relevancy, context precision, context recall, hallucination) while still capturing Flotorch gateway telemetry as documented in the [Flotorch Eval repo](https://github.com/FissionAI/flotorch-eval/tree/develop). This mode is showcased later in the notebook.\n","\n","In this notebook we rely on the DeepEval pathway to ensure network security guidance always references the exact encryption suites, access controls, and monitoring playbooks documented in the source guide.\n","\n","---\n","\n","### **Requirements**\n","\n","- Flotorch account with configured LLM, embedding model, and Network Security Knowledge Base.  \n","- `gt.json` (or another ground-truth file) containing network security protocol Q&A pairs for evaluation.  \n","- `prompt.json` containing the system and user prompt templates tailored to network security analysts.\n","\n","---\n","#### **Documentation References**\n","- [**flotorch-eval GitHub repo**](https://github.com/FissionAI/flotorch-eval/tree/develop) — reference implementation with sample notebooks and evaluation pipelines.  \n","- [**DeepEval Context Recall Documentation**](https://deepeval.com/docs/metrics-contextual-recall) — detailed explanation of the context recall metric."]},{"cell_type":"markdown","metadata":{"id":"e2a09f3e"},"source":["## 1. Install Dependencies\n","\n","First, we install the two necessary libraries. The `-q` flag is for a \"quiet\" installation, hiding the lengthy output.\n","\n","-   `flotorch`: The main Python SDK for interacting with all Flotorch services, including LLMs and Knowledge Bases.\n","-   `flotorch-eval[llm]`: The evaluation library. We use the `[llm]` extra to install dependencies required for LLM-based (Ragas) evaluations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwnpCfiUXfJ_"},"outputs":[],"source":["# Install flotorch-sdk and flotorch-core\n","# You can safely ignore dependency errors during installation.\n","\n","%pip install flotorch==3.1.0b1 flotorch-eval==2.0.0\n","%pip install opentelemetry-instrumentation-httpx==0.58b0"]},{"cell_type":"markdown","metadata":{"id":"e4418652"},"source":["## 2. Configure Environment\n","\n","This is the main configuration step. Set your API key, base URL, and the model names you want to use.\n","\n","-   **`FLOTORCH_API_KEY`**: Your Flotorch API key (found in your Flotorch Console).\n","-   **`FLOTORCH_BASE_URL`**: Your Flotorch console instance URL.\n","-   **`inference_model_name`**: The LLM your agent uses to *generate* answers (your 'agent's brain').\n","-   **`evaluation_llm_model_name`**: The LLM used to *evaluate* the answers (the 'evaluator's brain'). This is typically a powerful, separate model like `flotorch/gpt-4o` to ensure an unbiased, high-quality judgment.\n","-   **`evaluation_embedding_model_name`**: The embedding model used for semantic similarity checks during evaluation.\n","-   **`knowledge_base_repo`**: The ID of your Flotorch Knowledge Base, which acts as the 'source of truth' for your RAG agent.\n","\n","### Example :\n","\n","| Parameter | Description | Example |\n","|-----------|-------------|---------|\n","| `FLOTORCH_API_KEY` | Your API authentication key | `sk_...` |\n","| `FLOTORCH_BASE_URL` | Gateway endpoint | `https://gateway.flotorch.cloud` |\n","| `inference_model_name` | The LLM your agent uses to generate answers | `flotorch/gpt-4o-mini` |\n","| `evaluation_llm_model_name` | The LLM used to evaluate the answers | `flotorch/gpt-4o` |\n","| `evaluation_embedding_model_name` | Embedding model for semantic similarity checks | `open-ai/text-embedding-ada-002` |\n","| `knowledge_base_repo` | The ID of your Flotorch Knowledge Base | `digital-twin` |"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVfI3usASn2u"},"outputs":[],"source":["import getpass  # Securely prompt without echoing in Prefect/notebooks\n","\n","# Prefect-side authentication for Flotorch access\n","try:\n","    FLOTORCH_API_KEY = getpass.getpass(\"Paste your API key here: \")  # Used by Prefect flow and local runs\n","    print(f\"Success\")\n","except getpass.GetPassWarning as e:\n","    print(f\"Warning: {e}\")\n","    FLOTORCH_API_KEY = \"\"\n","\n","FLOTORCH_BASE_URL = input(\"Paste your Flotorch Base URL here: \")  # Prefect gateway or cloud endpoint\n","\n","inference_model_name = \"flotorch/<your-model-name>\"  # Model generating answers\n","evaluation_llm_model_name = \"flotorch/<your_model_name>\"  # Model judging answer quality\n","evaluation_embedding_model_name = \"flotorch/<embedding_model_name>\"  # Embedding model for similarity checks\n","\n","knowledge_base_repo = \"<your_knowledge_base_id>\" #Knowledge_base ID"]},{"cell_type":"markdown","metadata":{"id":"76978434"},"source":["## 3. Import Required Libraries\n","\n","### Purpose\n","Import all required components for evaluating the RAG assistant.\n","\n","### Key Components\n","- `json` : Loads configuration files and ground truth data from disk\n","- `tqdm` : Shows a lightweight progress bar while iterating over evaluation items\n","- `FlotorchLLM` : Connects to the Flotorch inference endpoint for answer generation\n","- `FlotorchVectorStore` : Retrieves context snippets from the configured knowledge base\n","- `memory_utils` : Utility helpers for extracting text from vector-store search results\n","- `LLMEvaluator`, EvaluationItem, MetricKey** : Runs metric scoring for the generated answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RRnnoQfXbOM"},"outputs":[],"source":["#Required imports\n","import json\n","from typing import List\n","from tqdm import tqdm # Use standard tqdm for simple progress bars\n","from google.colab import files\n","\n","# Flotorch SDK components\n","from flotorch.sdk.llm import FlotorchLLM\n","from flotorch.sdk.memory import FlotorchVectorStore\n","from flotorch.sdk.utils import memory_utils\n","\n","# Flotorch Eval components\n","from flotorch_eval.llm_eval import LLMEvaluator, EvaluationItem, MetricKey\n","from flotorch_eval.llm_eval import display_llm_evaluation_results\n","\n","print(\"Imported necessary libraries successfully\")"]},{"cell_type":"markdown","metadata":{"id":"8E6DGAqY7nPS"},"source":["## 4. Load Data and Prompts\n","\n","### Purpose\n","Here, we load our ground truth questions (`gt.json`) and the agent prompts (`prompt.json`) from local\n","files.\n","\n","### Files Required\n","\n","**1. `gt.json` (Ground Truth)**  \n","Contains question-answer pairs for evaluation. Each `answer` is the expected correct response.\n","\n","```json\n","[\n","  {\n","    \"question\": \"What port does LDAPS (LDAP over SSL/TLS) use?\",\n","    \"answer\": \"LDAPS uses port 636.\"\n","  },\n","  {\n","    \"question\": \"What ports does RADIUS use for authentication and accounting?\",\n","    \"answer\": \"RADIUS uses UDP port 1812 for authentication and port 1813 for accounting.\"\n","  }\n","]\n","```\n","\n","**2. `prompt.json` (Agent Prompts)**  \n","Defines the system prompt and user prompt template with `{context}` and `{question}` placeholders for dynamic formatting.\n","\n","```json\n","{\n","  \"system_prompt\": \"You are a helpful Network Security assistant. Answer based only on the context provided.\",\n","  \"user_prompt_template\": \"Context:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n","}\n","```\n","\n","### Instructions\n","Update `gt_path` and `prompt_path` variables in the next cell to point to your local file locations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFYSNDJo1MAP"},"outputs":[],"source":["print(\"Please upload your Ground Truth file (gt.json)\")\n","gt_upload = files.upload()\n","\n","gt_path = list(gt_upload.keys())[0]\n","with open(gt_path, 'r') as f:\n","    ground_truth = json.load(f)\n","print(f\"Ground truth loaded successfully — {len(ground_truth)} items\\n\")\n","\n","\n","print(\"Please upload your Prompts file (prompts.json)\")\n","prompts_upload = files.upload()\n","\n","prompts_path = list(prompts_upload.keys())[0]\n","with open(prompts_path, 'r') as f:\n","    prompt_config = json.load(f)\n","print(f\"Prompts loaded successfully — {len(prompt_config)} prompt pairs\")"]},{"cell_type":"markdown","metadata":{"id":"1d4b680f"},"source":["## 5. Define Helper Function\n","\n","### Purpose\n","Create a prompt-formatting helper for LLM message construction.\n","\n","### Functionality\n","The `create_messages` function:\n","- Builds the final prompt that will be sent to the LLM.\n","- Accepts system prompt, user prompt template, question, and retrieved context chunks\n","- Replaces `{context}` and `{question}` placeholders in the user prompt\n","- Returns a structured message list with (`{role: ..., content: ...}`) fields ready for LLM consumption"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aC4hMY5Ucdo4"},"outputs":[],"source":["def create_messages(system_prompt: str, user_prompt_template: str, question: str, context: List[str] = None):\n","    \"\"\"\n","    Creates a list of messages for the LLM based on the provided prompts, question, and optional context.\n","    \"\"\"\n","    context_text = \"\"\n","    if context:\n","        if isinstance(context, list):\n","            context_text = \"\\n\\n---\\n\\n\".join(context)\n","        elif isinstance(context, str):\n","            context_text = context\n","\n","    # Format the user prompt template\n","    user_content = user_prompt_template.replace(\"{context}\", context_text).replace(\"{question}\", question)\n","\n","    messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": user_content}\n","    ]\n","    return messages"]},{"cell_type":"markdown","metadata":{"id":"76e336e1"},"source":["## 6. Initialize Clients\n","\n","### Purpose\n","Set up the infrastructure for RAG pipeline execution.\n","\n","### Components Initialized\n","1. **FlotorchLLM** (`inference_llm`): Connects to the LLM endpoint for generating answers based on retrieved context\n","2. **FlotorchVectorStore** (`kb`): Connects to the Knowledge Base for semantic search and context retrieval\n","3. **Prompt Variables**: Extracts system prompt and user prompt template from `prompt_config` for dynamic message formatting\n","\n","These clients power the evaluation loop by retrieving relevant context and generating answers for each question."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a66f8510"},"outputs":[],"source":["# 1. Set up the LLM for generating answers\n","inference_llm = FlotorchLLM(\n","    api_key=FLOTORCH_API_KEY,\n","    base_url=FLOTORCH_BASE_URL,\n","    model_id=inference_model_name\n",")\n","\n","# 2. Set up the Knowledge Base connection\n","kb = FlotorchVectorStore(\n","    api_key=FLOTORCH_API_KEY,\n","    base_url=FLOTORCH_BASE_URL,\n","    vectorstore_id=knowledge_base_repo\n",")\n","\n","# 3. Load prompts into variables\n","system_prompt = prompt_config.get(\"system_prompt\", \"\")\n","user_prompt_template = prompt_config.get(\"user_prompt_template\", \"{question}\")\n","\n","print(\"Models and Knowledge Base are ready.\")"]},{"cell_type":"markdown","metadata":{"id":"f51660d1"},"source":["## 7. Run Experiment Loop\n","\n","### Purpose\n","Execute the full DeepEval for each question to generate answers for evaluation.\n","\n","### Pipeline Steps\n","For each question in `ground_truth`, the loop performs:\n","\n","1. **Retrieve Context**: Searches the Knowledge Base (`kb.search()`) to fetch relevant context passages\n","2. **Build Messages**: Uses `create_messages()` to format the system prompt, user prompt, question, and retrieved context into LLM-ready messages\n","3. **Generate Answer**: Invokes the inference LLM (`inference_llm.invoke()`) with `return_headers=True` to capture response metadata (cost, latency, tokens)\n","4. **Store for Evaluation**: Packages question, generated answer, expected answer, context, and metadata into an `EvaluationItem` object\n","\n","### Error Handling\n","A `try...except` block gracefully handles API failures, storing error messages as evaluation items to ensure the loop completes without crashes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0e37ac2"},"outputs":[],"source":["evaluation_items = [] # This will store our results\n","\n","# Use simple tqdm for a progress bar\n","print(f\"Running experiment on {len(ground_truth)} items...\")\n","\n","for qa in tqdm(ground_truth):\n","    question = qa.get(\"question\", \"\")\n","    gt_answer = qa.get(\"answer\", \"\")\n","\n","    try:\n","        # --- 1. Retrieve Context ---\n","        search_results = kb.search(query=question)\n","        context_texts = memory_utils.extract_vectorstore_texts(search_results)\n","\n","        # --- 2. Build Messages ---\n","        messages = create_messages(\n","            system_prompt=system_prompt,\n","            user_prompt_template=user_prompt_template,\n","            question=question,\n","            context=context_texts\n","        )\n","\n","        # --- 3. Generate Answer ---\n","        response, headers = inference_llm.invoke(messages=messages, return_headers=True)\n","        generated_answer = response.content\n","\n","        # --- 4. Store for Evaluation ---\n","        evaluation_items.append(EvaluationItem(\n","            question=question,\n","            generated_answer=generated_answer,\n","            expected_answer=gt_answer,\n","            context=context_texts, # Store the context for later display\n","            metadata=headers,\n","        ))\n","\n","    except Exception as e:\n","        print(f\"[ERROR] Failed on question '{question[:50]}...': {e}\")\n","        # Store a failure case so we can see it\n","        evaluation_items.append(EvaluationItem(\n","            question=question,\n","            generated_answer=f\"Error: {e}\",\n","            expected_answer=gt_answer,\n","            context=[],\n","            metadata={\"error\": str(e)},\n","        ))\n","\n","print(f\"Experiment completed. {len(evaluation_items)} items are ready for evaluation.\")"]},{"cell_type":"markdown","metadata":{"id":"crt03A2aphia"},"source":["## 8. Initialize the Evaluator (DeepEval)\n","\n","### Using DeepEval Context Recall\n","\n","Now that we have our `evaluation_items` list (containing the generated answers), we switch the `LLMEvaluator` to the **DeepEval** backend so every score reflects how completely the retrieved passages cover the required network security facts.\n","\n","This class remains the *“head judge”* for the evaluation loop; we’re simply selecting the DeepEval rubric that specializes in context adequacy for encryption suites, AAA flows, VPN modes, and detection runbooks.\n","\n","### Parameter Insights (DeepEval Mode)\n","\n","- **`api_key` / `base_url`** — Standard credentials used to authenticate and connect with the Flotorch-Eval service.  \n","- **`inferencer_model` / `embedding_model`** — DeepEval-powered scoring still needs the evaluator LLM and embeddings for semantic checks.  \n","- **`evaluation_engine=\"deepeval\"`** — Routes metrics through DeepEval, which (per the [flotorch-eval repository](https://github.com/FissionAI/flotorch-eval/tree/develop)) unlocks the following metric keys:  \n","  - **`MetricKey.FAITHFULNESS`**\n","  - **`MetricKey.ANSWER_RELEVANCY`**\n","  - **`MetricKey.CONTEXT_RELEVANCY`**\n","  - **`MetricKey.CONTEXT_PRECISION`**\n","  - **`MetricKey.CONTEXT_RECALL`**\n","  - **`MetricKey.HALLUCINATION`**\n","  These are the same metrics surfaced in Flotorch’s *auto* mode when Ragas prerequisites (like embeddings) are missing.  \n","- **`metrics`** — For this notebook we register only `MetricKey.CONTEXT_RECALL`, keeping the focus on whether the retrieved snippets contain every protocol detail needed.  \n","- **`metric_configs`** — Pass DeepEval-specific arguments such as a `\"threshold\"` (e.g., `0.8`) to trigger pass/fail decisions.  \n","- **Thresholds** — Set between `0.0–1.0`; network security reviews often target `1.0` to ensure no encryption, AAA, or VPN step is missed.\n","\n","DeepEval’s contextual recall rubric expects each test case to include the `input`, `actual_output`, `expected_output`, and `retrieval_context` fields so it can compare the gold-standard answer with the passages returned by your retriever. The judge extracts every statement from the `expected_output` and computes the percentage that can be attributed to at least one snippet in the `retrieval_context`, i.e., `Contextual Recall = attributable statements / total statements`, as documented in the official guidance ([DeepEval Contextual Recall docs](https://deepeval.com/docs/metrics-contextual-recall)).\n","\n","### DeepEval Context Recall Metric\n","\n","**Definition**: verifies that the retrieved network security context fully covers the facts referenced in the generated answer using the [DeepEval context recall rubric](https://deepeval.com/docs/metrics-contextual-recall). A score of 1 means every critical detail (cipher choice, tunnel mode, authentication exchange, IDS response) appears in the supporting snippets; anything below the threshold signals missing evidence.\n","\n","**How It Works**:\n","1. DeepEval extracts key facts from the answer using a grading LLM.  \n","2. Each fact is checked against the retrieved network security passages, with rationales describing any missing coverage.  \n","3. The final context-recall score reflects the proportion of supported facts and is compared against the configured threshold.  \n","\n","**Example**:\n","\n","*Question*: \"Describe the TLS 1.3 handshake phases and why forward secrecy matters.\"\n","\n","- *Pass Scenario* (Score = 1.0): The answer cites the retrieved TLS section explaining ClientHello, ServerHello, certificate validation, ECDHE key exchange, and confirms forward secrecy requirements.  \n","- *Fail Scenario* (Score = 0.0): The answer mentions forward secrecy but the retrieved snippets only cover IPsec tunnel mode, so DeepEval flags the missing TLS context and the evaluation fails.  \n","\n","This mirrors the broader RAG workflow while delivering guardrail-ready signals tailored to network security coverage.  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5e9f8a1"},"outputs":[],"source":["# Configure DeepEval Context Recall thresholds\n","metric_args = {\n","    \"context_recall\": {\"threshold\": 0.7},\n","}\n","\n","# Initialize the LLMEvaluator client\n","evaluator_client = LLMEvaluator(\n","    api_key=FLOTORCH_API_KEY,\n","    base_url=FLOTORCH_BASE_URL,\n","    embedding_model=evaluation_embedding_model_name,\n","    inferencer_model=evaluation_llm_model_name,\n","    metrics=[\n","        MetricKey.CONTEXT_RECALL,\n","    ],\n","    evaluation_engine=\"deepeval\",\n","    metric_configs=metric_args\n",")\n","\n","print(\"LLMEvaluator client initialized.\")"]},{"cell_type":"markdown","metadata":{"id":"a4d3b6f0"},"source":["## 9. Run Evaluation (DeepEval)\n","\n","### Purpose\n","Execute the evaluation process to score all generated answers using the **Context Recall** metric.\n","\n","### Process\n","- Call either:\n","  - `evaluator_client.evaluate()` for **synchronous** (sequential) execution, or  \n","  - `evaluator_client.aevaluate()` for **asynchronous** (concurrent) execution  \n","  using the complete list of `evaluation_items`.\n","\n","- For each evaluation item:\n","  - The evaluator scores **Context Recall** by comparing the generated answer against the retrieved context.\n","\n","- Collect the following outputs:\n","  - Context Recall scores\n","  - Gateway metrics (cost, latency, token usage)\n","  - Structured evaluation results\n","\n","### Output\n","- A complete evaluation report ready for analysis.\n","\n","> **Note:**  \n","> This step may take a few minutes, as it requires LLM calls for each question to compute  Aspect Critic scores.  \n","> Use the **synchronous** method for standard sequential execution, or the **Context Recall** method for faster, concurrent processing.\n","."]},{"cell_type":"markdown","source":["### Asynchronous Evaluation"],"metadata":{"id":"es__kB-qXAH2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1d0e3b2"},"outputs":[],"source":["print(\"Starting evaluation... This may take a few minutes.\")\n","\n","eval_results = await evaluator_client.aevaluate(evaluation_items)\n","\n","print(\"Evaluation complete.\")"]},{"cell_type":"markdown","source":["\n","### Synchronous Evaluation (uncomment the below code to use synchronous manner)"],"metadata":{"id":"weO7fVgaXEW-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQfFEEhhWaZz"},"outputs":[],"source":["# print(\"Starting evaluation... This may take a few minutes.\")\n","\n","# eval_results = evaluator_client.evaluate(evaluation_items)\n","\n","# print(\"Evaluation complete.\")"]},{"cell_type":"markdown","metadata":{"id":"e8f1c3a7"},"source":["## 10. View Per-Question Results (DeepEval)\n","\n","### Purpose\n","Display contextual recall scores in a compact table so security reviewers can confirm that each answer had the proper supporting passages retrieved."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40BGB_ltSmKy"},"outputs":[],"source":["display_llm_evaluation_results(eval_results)"]},{"cell_type":"markdown","metadata":{"id":"k8l9m0n1"},"source":["## 11. View Raw JSON Results\n","\n","### Purpose\n","Display the complete evaluation results in JSON format for detailed inspection and programmatic access.\n","\n","### Output Structure\n","The JSON output includes for each question:\n","- **model**: The evaluation LLM model used\n","- **input_query**: The original question\n","- **context**: Full retrieved context passages (not truncated)\n","- **generated_answer**: Complete LLM-generated response\n","- **groundtruth_answer**: Expected correct answer\n","- **evaluation_metrics**: Dictionary containing:\n","  - **context_recall**: DeepEval contextual recall score between `0` and `1`\n","  - **total_latency_ms**: Total evaluation time in milliseconds\n","  - **total_cost**: Cost of evaluation in USD\n","  - **total_tokens**: Token count for evaluation\n","\n","This raw JSON output is useful for follow-up audits, regression tracking, or downstream automation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2q3r4s5"},"outputs":[],"source":["print(\"--- Aggregate Evaluation Results ---\")\n","print(json.dumps(eval_results, indent=2))"]},{"cell_type":"markdown","metadata":{"id":"summary_cell_new"},"source":["## 12. Summary\n","\n","### What We Accomplished\n","\n","This notebook delivered an end-to-end workflow for evaluating a Network Security Protocol Advisor with Flotorch Eval using the DeepEval contextual recall metric.\n","\n","### Workflow Summary\n","\n","1. **Configured Infrastructure**\n","   - Set up `FlotorchLLM` for answer generation.  \n","   - Connected to `FlotorchVectorStore` for protocol retrieval.  \n","   - Initialized `LLMEvaluator` with the DeepEval engine targeting contextual recall.  \n","\n","2. **Generated Responses**\n","   - Loaded network security ground-truth questions from `network_security_gt.json`.  \n","   - Retrieved relevant guide excerpts for each question.  \n","   - Generated answers with the inference LLM and captured gateway metadata (latency, cost, tokens).  \n","\n","3. **Evaluated Contextual Recall**\n","   - Ran DeepEval contextual recall scoring over every response.  \n","   - Verified whether each expected answer’s statements were supported by the retrieved context.  \n","   - Recorded contextual recall scores alongside gateway diagnostics for governance.  \n","\n","4. **Visualized Results**\n","   - Displayed per-question contextual recall scores in a reviewer-friendly table.  \n","   - Exported the full JSON payload for auditing or automation.  \n","\n","### Key Takeaways\n","\n","- **Context Recall = 1.0** signals complete retrieval coverage; lower scores highlight missing network security facts in the retrieved snippets.  \n","- DeepEval judges **Expected Answer ↔ Retrieved Context**, which is ideal for validating encryption, AAA, VPN, and detection guidance coverage.  \n","- Monitoring contextual recall keeps focus on retriever quality, helping SecOps teams close documentation gaps before they impact production playbooks."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"venve","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}