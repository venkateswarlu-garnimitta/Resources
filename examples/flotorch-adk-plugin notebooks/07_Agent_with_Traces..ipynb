{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6829303b",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/1KI6nyX4TvG7-0z4TMEE3ND9lvHujAR0P/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0eb013",
   "metadata": {},
   "source": [
    "# Advanced Agent Observability with `FlotorchADKAgent` Traces\n",
    "\n",
    "This notebook demonstrates how to build and monitor AI agents using the `FlotorchADKAgent` client. While the agent configuration (instructions, persona, model) is managed on the Flotorch platform, this guide specifically focuses on **Tracing and Observability**.\n",
    "\n",
    "### Why Traces Matter:\n",
    "In complex agentic workflows, understanding *why* an agent responded in a certain way is crucial. Tracing allows you to:\n",
    "* **Debug LLM Invocations:** See exactly what system instructions and prompts were sent.\n",
    "* **Monitor Performance:** Track latency across different stages (routing, guardrails, and provider calls).\n",
    "* **Audit Costs:** View token usage and cost calculations per turn.\n",
    "* **Verify Guardrails:** Confirm that input and output validations are functioning correctly.\n",
    "\n",
    "### Prerequisites\n",
    "1.  Configure your agent and API key in the [Flotorch Console](https://console.flotorch.cloud/).\n",
    "2.  Ensure you have an active agent name and a workspace API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa17a01",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "We begin by installing the `flotorch` library with ADK support and its dependencies. This provides the OpenTelemetry instrumentation required to capture traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9236b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install flotorch adk package with dependencies\n",
    "%pip install flotorch[adk]==3.1.4b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOTORCH_API_KEY = \"sk_...\"  # Update this with your flotorch Api key\n",
    "FLOTORCH_BASE_URL = \"https://gateway.flotorch.cloud\"\n",
    "AGENT_NAME = \"your-agent-name\"\n",
    "APP_NAME = \"observability_demo_app\"\n",
    "USER_ID = \"user_001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flotorch.adk.agent import FlotorchADKAgent\n",
    "from flotorch.adk.sessions import FlotorchADKSession\n",
    "from google.adk import Runner\n",
    "from google.genai import types\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3c13a",
   "metadata": {},
   "source": [
    "## 2. Initializing Agent with Tracer Configuration\n",
    "\n",
    "The key step for observability is passing the `tracer_config` to the `FlotorchADKAgent`. \n",
    "\n",
    "* **enabled**: Activates the collection of OpenTelemetry spans.\n",
    "* **endpoint**: The Flotorch observability collector that aggregates your trace data.\n",
    "* **sampling_rate**: Set to `1` to capture 100% of interactions (ideal for development/debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "flotorch_client = FlotorchADKAgent(\n",
    "    agent_name=AGENT_NAME,\n",
    "    api_key=FLOTORCH_API_KEY,\n",
    "    base_url=FLOTORCH_BASE_URL,\n",
    "    tracer_config={\n",
    "        \"enabled\": True,\n",
    "        \"endpoint\": \"<your_observability_endpoint>\",\n",
    "        \"sampling_rate\": 1 \n",
    "    }\n",
    ")\n",
    "\n",
    "agent = flotorch_client.get_agent()\n",
    "print(f\"Agent '{agent.name}' initialized with tracing enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf4658",
   "metadata": {},
   "source": [
    "## 3. Runner and Session Management\n",
    "\n",
    "We use the `Runner` to orchestrate the conversation and the `FlotorchADKSession` to maintain context. Every interaction through this runner will now generate a trace linked to the `session_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = FlotorchADKSession(\n",
    "    api_key=FLOTORCH_API_KEY,\n",
    "    base_url=FLOTORCH_BASE_URL\n",
    ")\n",
    "    \n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be0173",
   "metadata": {},
   "source": [
    "## 4. Executing an Instrumented Interaction\n",
    "\n",
    "When we run the `chat_with_agent` function, the ADK automatically wraps the request in a trace. It captures the internal steps like session lookup, LLM routing, and the final response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c169a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_turn(query, session_id, user_id, runner):\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "    events = runner.run(user_id=user_id, session_id=session_id, new_message=content)\n",
    "\n",
    "    for event in events:\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                return event.content.parts[0].text\n",
    "    return \"Error: No response.\"\n",
    "\n",
    "async def chat_with_agent(query, session_id):\n",
    "    return run_single_turn(query, session_id, USER_ID, runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e80d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = await runner.session_service.create_session(app_name=APP_NAME, user_id=USER_ID)\n",
    "response = await chat_with_agent(\"Hello, I am John\", session.id)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trace_doc_1",
   "metadata": {},
   "source": [
    "## 5. Extracting Trace Identifiers\n",
    "\n",
    "After the interaction, we can retrieve the specific `trace_id` generated for the session. This ID acts as a unique fingerprint for the entire request-response lifecycle. You can use this ID to find logs in the Flotorch UI or to query the raw trace data programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ids = flotorch_client.get_tracer_ids()\n",
    "print(f\"Captured Trace IDs: {trace_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trace_doc_2",
   "metadata": {},
   "source": [
    "## 6. Inspecting Raw Trace Data\n",
    "\n",
    "The `get_traces()` method provides a deep look into the agent's internal reasoning. The trace is structured into **Spans**, which represent individual operations:\n",
    "\n",
    "### Key Span Components in the Output:\n",
    "* **`invoke_agent`**: The root span covering the total duration of the request.\n",
    "* **`call_llm`**: Contains the raw prompt and the system instruction used by the agent.\n",
    "* **`guardrails.input/output`**: Details whether the content was flagged or blocked.\n",
    "* **`cost.calculation`**: Breaks down `input_tokens`, `output_tokens`, and the estimated cost in USD.\n",
    "* **`provider.api_call`**: Shows the specific model version (e.g., `gpt-4o`) and the provider latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "traces = flotorch_client.get_traces()\n",
    "print(json.dumps(traces, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8a235",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we moved beyond basic agent interaction to implement a fully observable system using `FlotorchADKAgent`.\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Transparent Logic**: We used traces to reveal the system instructions and model configurations being pulled from the Flotorch platform.\n",
    "- **Performance Monitoring**: We identified how to track latency across multiple spans, from internal routing to external LLM calls.\n",
    "- **Resource Management**: The traces provided granular token usage and cost data, essential for scaling production applications.\n",
    "- **Simplified Debugging**: By using `trace_id`, developers can pinpoint failures in the Flotorch console without manually digging through logs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
